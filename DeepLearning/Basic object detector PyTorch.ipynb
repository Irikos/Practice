{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "73b37794",
   "metadata": {},
   "source": [
    "### Training an object detector from scratch in PyTorch\n",
    "#### Link: https://pyimagesearch.com/2021/11/01/training-an-object-detector-from-scratch-in-pytorch/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "140bffde",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "from torch.nn import Dropout\n",
    "from torch.nn import Identity\n",
    "from torch.nn import Linear\n",
    "from torch.nn import Module\n",
    "from torch.nn import ReLU\n",
    "from torch.nn import Sequential\n",
    "from torch.nn import Sigmoid\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from torch.nn import MSELoss\n",
    "from torch.optim import Adam\n",
    "from torchvision.models import resnet50\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imutils import paths\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pickle\n",
    "import torch\n",
    "import time\n",
    "import cv2\n",
    "import os\n",
    "\n",
    "\n",
    "\n",
    "import mimetypes\n",
    "import argparse\n",
    "import imutils\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "63f4e650",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Config ###\n",
    "\n",
    "# path to the input dataset from which we derive the images and annotation files\n",
    "BASE_PATH = \"/home/irikos/Work/datasets/\"\n",
    "IMAGES_PATH = os.path.sep.join([BASE_PATH, \"images\"])\n",
    "ANNOTS_PATH = os.path.sep.join([BASE_PATH, \"annotations\"])\n",
    "\n",
    "BASE_OUTPUT = \"output\"\n",
    "\n",
    "# define the path to the output model, label encoder, plots output directory and testing image paths\n",
    "MODEL_PATH = os.path.sep.join([BASE_OUTPUT, \"detector.pth\"])\n",
    "LE_PATH = os.path.sep.join([BASE_OUTPUT, \"le.pickle\"])\n",
    "PLOTS_PATH = os.path.sep.join([BASE_OUTPUT, \"plots\"])\n",
    "TEST_PATHS = os.path.sep.join([BASE_OUTPUT, \"test_paths.txt\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5acacb12",
   "metadata": {},
   "outputs": [],
   "source": [
    "### HYPERPARAMETERS ###\n",
    "\n",
    "# determine the current device and based on that set the pin memory\n",
    "# flag\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "PIN_MEMORY = True if DEVICE == \"cuda\" else False\n",
    "\n",
    "# specify ImageNet mean and standard deviation\n",
    "MEAN = [0.485, 0.456, 0.406]\n",
    "STD = [0.229, 0.224, 0.225]\n",
    "\n",
    "# initialize our initial learning rate, number of epochs to train\n",
    "# for, and the batch size\n",
    "INIT_LR = 1e-4\n",
    "NUM_EPOCHS = 20\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "# specify the loss weights\n",
    "LABELS = 1.0\n",
    "BBOX = 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d883ab4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "### CUSTOM TENSOR DATASET ###\n",
    "class CustomTensorDataset(Dataset):\n",
    "    def __init__(self, tensors, transforms=None):\n",
    "        self.tensors = tensors\n",
    "        self.transforms = transforms\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        # grab the image, label and its bbox coordinates\n",
    "        image = self.tensors[0][index]\n",
    "        label = self.tensors[1][index]\n",
    "        bbox = self.tensors[2][index]\n",
    "        \n",
    "        # transpose the image such that its channel dimensions becomes the leading one\n",
    "        # PyTorch requirements. Basically move from Height x Width x Channels to\n",
    "        # Channels x Height x Width\n",
    "        image = image.permute(2, 0, 1)\n",
    "        \n",
    "        # check to see if we have any image transformations to apply and, if so, apply them\n",
    "        if self.transforms:\n",
    "            image = self.transforms(image)\n",
    "            \n",
    "        # return a tuble of images, labels and bounding box coordinates\n",
    "        return (image, label, bbox)\n",
    "    \n",
    "    def __len__(self):\n",
    "        # return the size of the dataset\n",
    "        return len(self.tensors[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "745bbf94",
   "metadata": {},
   "outputs": [],
   "source": [
    "### BBOX REGRESSOR ###\n",
    "class ObjectDetector(Module):\n",
    "    def __init__(self, baseModel, numClasses):\n",
    "        super(ObjectDetector, self).__init__()\n",
    "        \n",
    "        # initialize the base model and the number of classes\n",
    "        self.baseModel = baseModel\n",
    "        self.numClasses = numClasses\n",
    "        \n",
    "        # build the regressor head for outputting the bounding box coordinates\n",
    "        self.regressor = Sequential(\n",
    "            Linear(baseModel.fc.in_features, 128),\n",
    "            ReLU(),\n",
    "            Linear(128, 64),\n",
    "            ReLU(),\n",
    "            Linear(64, 32),\n",
    "            ReLU(),\n",
    "            Linear(32, 4),\n",
    "            Sigmoid()\n",
    "        )\n",
    "        \n",
    "        # build the classifier head to predict the class labels\n",
    "        self.classifier = Sequential(\n",
    "            Linear(baseModel.fc.in_features, 512),\n",
    "            ReLU(),\n",
    "            Dropout(),\n",
    "            Linear(512, 512),\n",
    "            ReLU(),\n",
    "            Dropout(),\n",
    "            Linear(512, self.numClasses)\n",
    "        )\n",
    "    \n",
    "        # set the classifier of our base model to produce outputs from the last convolution block\n",
    "        self.baseModel.fc = Identity()\n",
    "        \n",
    "    def forward(self, X):\n",
    "        # pass the inputs through the base model and then obtain predictions\n",
    "        # from two different branches of the network\n",
    "        features = self.baseModel(X)\n",
    "        bboxes = self.regressor(features)\n",
    "        classLogits = self.classifier(features)\n",
    "        \n",
    "        # return the outputs as a tuple\n",
    "        return (bboxes, classLogits)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a0136857",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] loading dataset...\n"
     ]
    }
   ],
   "source": [
    "### TRAINING ###\n",
    "\n",
    "# initialize the list of data (images), class labels, target bounding box coordinates and image paths\n",
    "print(\"[INFO] loading dataset...\")\n",
    "data = []\n",
    "labels = []\n",
    "bboxes = []\n",
    "imagePaths = []\n",
    "\n",
    "for csvPath in paths.list_files(ANNOTS_PATH, validExts=(\".txt\")):\n",
    "    rows = open(csvPath).read().strip().split(\"\\n\")\n",
    "    \n",
    "    # loop over the rows\n",
    "    for row in rows:\n",
    "        # break fow into filename, bbox coords and class label\n",
    "        row = row.split(\",\")\n",
    "        (filename, startX, startY, endX, endY, label) = row\n",
    "        \n",
    "        # derive the path to the input image, load the image (in openCV format) and grab its dimensions\n",
    "        imagePath = os.path.sep.join([IMAGES_PATH, filename])\n",
    "        \n",
    "        image = cv2.imread(imagePath)\n",
    "        (h, w) = image.shape[:2]\n",
    "        \n",
    "        # scale the bbox coords relative to the spatial dim for the input image\n",
    "        \n",
    "        startX = float(startX) / w\n",
    "        startY = float(startY) / h\n",
    "        endX = float(endX) / w\n",
    "        endY = float(endY) / h\n",
    "        \n",
    "        # load the image and preprocess it\n",
    "        image = cv2.imread(imagePath)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        image = cv2.resize(image, (224, 224))\n",
    "        \n",
    "        # update our lists of data, class labels, bboxes and image paths\n",
    "        data.append(image)\n",
    "        labels.append(label)\n",
    "        bboxes.append((startX, startY, endX, endY))\n",
    "        imagePaths.append(imagePath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8a5f305e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.array(data, dtype=\"float32\")\n",
    "labels = np.array(labels)\n",
    "bboxes = np.array(bboxes, dtype=\"float32\")\n",
    "imagePaths = np.array(imagePaths)\n",
    "\n",
    "# perform label encoding on the labels\n",
    "le = LabelEncoder()\n",
    "labels = le.fit_transform(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5ae81800",
   "metadata": {},
   "outputs": [],
   "source": [
    "# partition the data into training and testing splits using 80% - 20%\n",
    "split = train_test_split(data, labels, bboxes, imagePaths, test_size=0.2, random_state=42)\n",
    "\n",
    "# unpack the data split\n",
    "(trainImages, testImages) = split[:2]\n",
    "(trainLabels, testLabels) = split[2:4]\n",
    "(trainBBoxes, testBBoxes) = split[4:6]\n",
    "(trainPaths, testPaths) = split[6:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4f7b738b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert NumPy arrays to PyTorch tensors\n",
    "(trainImages, testImages) = torch.tensor(trainImages), torch.tensor(testImages)\n",
    "(trainLabels, testLabels) = torch.tensor(trainLabels), torch.tensor(testLabels)\n",
    "(trainBBoxes, testBBoxes) = torch.tensor(trainBBoxes), torch.tensor(testBBoxes)\n",
    "\n",
    "# define normalization transforms\n",
    "transforms = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=MEAN, std=STD)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "1f84b5a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] total training samples: 1394...\n",
      "[INFO] total test samples: 349...\n"
     ]
    }
   ],
   "source": [
    "# convert NumPy arrays to PyTorch datasets\n",
    "trainDS = CustomTensorDataset((trainImages, trainLabels, trainBBoxes), transforms=transforms)\n",
    "testDS = CustomTensorDataset((testImages, testLabels, testBBoxes), transforms=transforms)\n",
    "print(\"[INFO] total training samples: {}...\".format(len(trainDS)))\n",
    "print(\"[INFO] total test samples: {}...\".format(len(testDS)))\n",
    "\n",
    "# calculate steps per epoch for training and validation set\n",
    "trainSteps = len(trainDS) // BATCH_SIZE\n",
    "valSteps = len(testDS) // BATCH_SIZE\n",
    "\n",
    "# create data loaders\n",
    "trainLoader = DataLoader(trainDS, batch_size=BATCH_SIZE, shuffle=True, num_workers=os.cpu_count(), \n",
    "                         pin_memory=PIN_MEMORY)\n",
    "\n",
    "testLoader = DataLoader(testDS, batch_size=BATCH_SIZE, shuffle=True, num_workers=os.cpu_count(), \n",
    "                         pin_memory=PIN_MEMORY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5907e50c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] saving testing image paths...\n"
     ]
    }
   ],
   "source": [
    "# write the testing image paths to disk so that we can use then\n",
    "# when evaluating/testing our object detector\n",
    "print(\"[INFO] saving testing image paths...\")\n",
    "f = open(TEST_PATHS, \"w\")\n",
    "f.write(\"\\n\".join(testPaths))\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "25865bf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/irikos/anaconda3/envs/yolov5/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and will be removed in 0.15, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/irikos/anaconda3/envs/yolov5/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "# load the ResNet50 network as a base netowrk\n",
    "resnet = resnet50(pretrained=True)\n",
    "\n",
    "# freeze all ResNet50 layers so they will not be updated during the training process\n",
    "for params in resnet.parameters():\n",
    "    params.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b5816d78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ObjectDetector(\n",
      "  (baseModel): ResNet(\n",
      "    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "    (layer1): Sequential(\n",
      "      (0): Bottleneck(\n",
      "        (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (downsample): Sequential(\n",
      "          (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1): Bottleneck(\n",
      "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (2): Bottleneck(\n",
      "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (layer2): Sequential(\n",
      "      (0): Bottleneck(\n",
      "        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (downsample): Sequential(\n",
      "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1): Bottleneck(\n",
      "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (2): Bottleneck(\n",
      "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (3): Bottleneck(\n",
      "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (layer3): Sequential(\n",
      "      (0): Bottleneck(\n",
      "        (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (downsample): Sequential(\n",
      "          (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "          (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1): Bottleneck(\n",
      "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (2): Bottleneck(\n",
      "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (3): Bottleneck(\n",
      "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (4): Bottleneck(\n",
      "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (5): Bottleneck(\n",
      "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (layer4): Sequential(\n",
      "      (0): Bottleneck(\n",
      "        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (downsample): Sequential(\n",
      "          (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "          (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1): Bottleneck(\n",
      "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (2): Bottleneck(\n",
      "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "    (fc): Identity()\n",
      "  )\n",
      "  (regressor): Sequential(\n",
      "    (0): Linear(in_features=2048, out_features=128, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=128, out_features=64, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=64, out_features=32, bias=True)\n",
      "    (5): ReLU()\n",
      "    (6): Linear(in_features=32, out_features=4, bias=True)\n",
      "    (7): Sigmoid()\n",
      "  )\n",
      "  (classifier): Sequential(\n",
      "    (0): Linear(in_features=2048, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Dropout(p=0.5, inplace=False)\n",
      "    (3): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (4): ReLU()\n",
      "    (5): Dropout(p=0.5, inplace=False)\n",
      "    (6): Linear(in_features=512, out_features=1, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# create or custom object detector model and flash it to the current device\n",
    "objectDetector = ObjectDetector(resnet, len(le.classes_))\n",
    "objectDetector = objectDetector.to(DEVICE)\n",
    "\n",
    "# define our loss functions\n",
    "classLossFunc = CrossEntropyLoss()\n",
    "bboxLossFunc = MSELoss()\n",
    "\n",
    "# initialize the optimizer, compile the model and show the model summary\n",
    "opt = Adam(objectDetector.parameters(), lr=INIT_LR)\n",
    "print(objectDetector)\n",
    "\n",
    "# initialize a dictionary to store training history\n",
    "H = {\"total_train_loss\": [], \"total_val_loss\": [], \"train_class_acc\": [], \"val_class_acc\": []}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "5f045899",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] training the network...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|█████                                                                                               | 1/20 [00:03<01:02,  3.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] EPOCH: 1/20\n",
      "Train loss: 0.008924, Train accuracy: 1.0000\n",
      "Val loss: 0.008989, Val accuracy: 1.0000\n",
      "[INFO] total time taken to train the model: 3.30s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 10%|██████████                                                                                          | 2/20 [00:06<01:02,  3.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] EPOCH: 2/20\n",
      "Train loss: 0.008643, Train accuracy: 1.0000\n",
      "Val loss: 0.008857, Val accuracy: 1.0000\n",
      "[INFO] total time taken to train the model: 6.90s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 15%|███████████████                                                                                     | 3/20 [00:10<00:57,  3.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] EPOCH: 3/20\n",
      "Train loss: 0.008528, Train accuracy: 1.0000\n",
      "Val loss: 0.008732, Val accuracy: 1.0000\n",
      "[INFO] total time taken to train the model: 10.17s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 20%|████████████████████                                                                                | 4/20 [00:13<00:53,  3.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] EPOCH: 4/20\n",
      "Train loss: 0.008319, Train accuracy: 1.0000\n",
      "Val loss: 0.008571, Val accuracy: 1.0000\n",
      "[INFO] total time taken to train the model: 13.40s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 25%|█████████████████████████                                                                           | 5/20 [00:16<00:49,  3.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] EPOCH: 5/20\n",
      "Train loss: 0.008155, Train accuracy: 1.0000\n",
      "Val loss: 0.008468, Val accuracy: 1.0000\n",
      "[INFO] total time taken to train the model: 16.63s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 30%|██████████████████████████████                                                                      | 6/20 [00:19<00:45,  3.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] EPOCH: 6/20\n",
      "Train loss: 0.007996, Train accuracy: 1.0000\n",
      "Val loss: 0.008377, Val accuracy: 1.0000\n",
      "[INFO] total time taken to train the model: 19.89s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 35%|███████████████████████████████████                                                                 | 7/20 [00:24<00:46,  3.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] EPOCH: 7/20\n",
      "Train loss: 0.007935, Train accuracy: 1.0000\n",
      "Val loss: 0.008328, Val accuracy: 1.0000\n",
      "[INFO] total time taken to train the model: 24.00s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 40%|████████████████████████████████████████                                                            | 8/20 [00:27<00:41,  3.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] EPOCH: 8/20\n",
      "Train loss: 0.007771, Train accuracy: 1.0000\n",
      "Val loss: 0.008207, Val accuracy: 1.0000\n",
      "[INFO] total time taken to train the model: 27.26s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 45%|█████████████████████████████████████████████                                                       | 9/20 [00:30<00:37,  3.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] EPOCH: 9/20\n",
      "Train loss: 0.007663, Train accuracy: 1.0000\n",
      "Val loss: 0.008133, Val accuracy: 1.0000\n",
      "[INFO] total time taken to train the model: 30.49s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 50%|█████████████████████████████████████████████████▌                                                 | 10/20 [00:33<00:33,  3.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] EPOCH: 10/20\n",
      "Train loss: 0.007598, Train accuracy: 1.0000\n",
      "Val loss: 0.008061, Val accuracy: 1.0000\n",
      "[INFO] total time taken to train the model: 33.73s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 55%|██████████████████████████████████████████████████████▍                                            | 11/20 [00:37<00:29,  3.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] EPOCH: 11/20\n",
      "Train loss: 0.007422, Train accuracy: 1.0000\n",
      "Val loss: 0.007997, Val accuracy: 1.0000\n",
      "[INFO] total time taken to train the model: 37.02s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 60%|███████████████████████████████████████████████████████████▍                                       | 12/20 [00:40<00:26,  3.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] EPOCH: 12/20\n",
      "Train loss: 0.007368, Train accuracy: 1.0000\n",
      "Val loss: 0.008017, Val accuracy: 1.0000\n",
      "[INFO] total time taken to train the model: 40.23s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 65%|████████████████████████████████████████████████████████████████▎                                  | 13/20 [00:43<00:22,  3.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] EPOCH: 13/20\n",
      "Train loss: 0.007341, Train accuracy: 1.0000\n",
      "Val loss: 0.007955, Val accuracy: 1.0000\n",
      "[INFO] total time taken to train the model: 43.46s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 70%|█████████████████████████████████████████████████████████████████████▎                             | 14/20 [00:46<00:19,  3.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] EPOCH: 14/20\n",
      "Train loss: 0.007216, Train accuracy: 1.0000\n",
      "Val loss: 0.008112, Val accuracy: 1.0000\n",
      "[INFO] total time taken to train the model: 46.70s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 75%|██████████████████████████████████████████████████████████████████████████▎                        | 15/20 [00:50<00:16,  3.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] EPOCH: 15/20\n",
      "Train loss: 0.007179, Train accuracy: 1.0000\n",
      "Val loss: 0.007823, Val accuracy: 1.0000\n",
      "[INFO] total time taken to train the model: 50.02s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 80%|███████████████████████████████████████████████████████████████████████████████▏                   | 16/20 [00:53<00:13,  3.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] EPOCH: 16/20\n",
      "Train loss: 0.007010, Train accuracy: 1.0000\n",
      "Val loss: 0.007869, Val accuracy: 1.0000\n",
      "[INFO] total time taken to train the model: 53.28s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 85%|████████████████████████████████████████████████████████████████████████████████████▏              | 17/20 [00:56<00:09,  3.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] EPOCH: 17/20\n",
      "Train loss: 0.006974, Train accuracy: 1.0000\n",
      "Val loss: 0.007850, Val accuracy: 1.0000\n",
      "[INFO] total time taken to train the model: 56.66s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 90%|█████████████████████████████████████████████████████████████████████████████████████████          | 18/20 [01:00<00:06,  3.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] EPOCH: 18/20\n",
      "Train loss: 0.006902, Train accuracy: 1.0000\n",
      "Val loss: 0.007686, Val accuracy: 1.0000\n",
      "[INFO] total time taken to train the model: 60.39s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 95%|██████████████████████████████████████████████████████████████████████████████████████████████     | 19/20 [01:03<00:03,  3.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] EPOCH: 19/20\n",
      "Train loss: 0.006838, Train accuracy: 1.0000\n",
      "Val loss: 0.008081, Val accuracy: 1.0000\n",
      "[INFO] total time taken to train the model: 63.67s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [01:06<00:00,  3.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] EPOCH: 20/20\n",
      "Train loss: 0.006955, Train accuracy: 1.0000\n",
      "Val loss: 0.007735, Val accuracy: 1.0000\n",
      "[INFO] total time taken to train the model: 66.97s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# loop over epochs\n",
    "print(\"[INFO] training the network...\")\n",
    "\n",
    "startTime = time.time()\n",
    "for e in tqdm(range(NUM_EPOCHS)):\n",
    "    objectDetector.train()\n",
    "    \n",
    "    # initialize the total trainign and validation loss\n",
    "    totalTrainLoss = 0\n",
    "    totalValLoss = 0\n",
    "    \n",
    "    # initialize the number of correct predictions in the training and validation step\n",
    "    trainCorrect = 0\n",
    "    valCorrect = 0\n",
    "    \n",
    "    for (images, labels, bboxes) in trainLoader:\n",
    "        (images, labels, bboxes) = (images.to(DEVICE), labels.to(DEVICE), bboxes.to(DEVICE))\n",
    "        \n",
    "        # perform a forward pass and calculate the training loss\n",
    "        predictions = objectDetector(images)\n",
    "        bboxLoss = bboxLossFunc(predictions[0], bboxes)\n",
    "        classLoss = classLossFunc(predictions[1], labels)\n",
    "        totalLoss = (BBOX * bboxLoss) + (LABELS * classLoss)\n",
    "        \n",
    "        # zero out the gradients, peform the backpropagation step and upgrade the weights\n",
    "        opt.zero_grad()\n",
    "        totalLoss.backward()\n",
    "        opt.step()\n",
    "        \n",
    "        # add the loss to the total training loss so far and calcul;ate the number of correct predictions\n",
    "        totalTrainLoss += totalLoss\n",
    "        trainCorrect += (predictions[1].argmax(1) == labels).type(torch.float).sum().item()\n",
    "        \n",
    "    # switch off autograd\n",
    "    with torch.no_grad():\n",
    "        objectDetector.eval()\n",
    "\n",
    "        # loop over the validatoon set\n",
    "\n",
    "        for (images, labels, bboxes) in testLoader:\n",
    "            (images, labels, bboxes) = (images.to(DEVICE), labels.to(DEVICE), bboxes.to(DEVICE))\n",
    "            \n",
    "            # make predictions and calculate the validation loss\n",
    "            predictions = objectDetector(images)\n",
    "            bboxLoss = bboxLossFunc(predictions[0], bboxes)\n",
    "            classLoss = classLossFunc(predictions[1], labels)\n",
    "            \n",
    "            totalLoss = (BBOX * bboxLoss) + (LABELS * classLoss)\n",
    "            totalValLoss += totalLoss\n",
    "            # calculate the number of correct predictions\n",
    "            valCorrect += (predictions[1].argmax(1) == labels).type(torch.float).sum().item()\n",
    "\n",
    "    # calculate tthe average training and validation loss\n",
    "    avgTrainLoss = totalTrainLoss / trainSteps\n",
    "    avgValLoss = totalValLoss / valSteps\n",
    "    \n",
    "    # calculate the training and vaalidation accuracy\n",
    "    trainCorrect = trainCorrect / len(trainDS)\n",
    "    valCorrect = valCorrect / len(testDS)\n",
    "    \n",
    "    # update our training history\n",
    "    H[\"total_train_loss\"].append(avgTrainLoss.cpu().detach().numpy())\n",
    "    H[\"train_class_acc\"].append(trainCorrect)\n",
    "    H[\"total_val_loss\"].append(avgValLoss.cpu().detach().numpy())\n",
    "    H[\"val_class_acc\"].append(valCorrect)\n",
    "    \n",
    "    \n",
    "    # print the model training and validation information\n",
    "    print(\"[INFO] EPOCH: {}/{}\".format(e + 1, NUM_EPOCHS))\n",
    "    print(\"Train loss: {:.6f}, Train accuracy: {:.4f}\".format(avgTrainLoss, trainCorrect))\n",
    "    print(\"Val loss: {:.6f}, Val accuracy: {:.4f}\".format(avgValLoss, valCorrect))\n",
    "    endTime = time.time()\n",
    "    print(\"[INFO] total time taken to train the model: {:.2f}s\".format(endTime - startTime))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "0328db1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] saving object detector model...\n",
      "[INFO] saving label encoder...\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# serialize the model to disk\n",
    "print(\"[INFO] saving object detector model...\")\n",
    "torch.save(objectDetector, MODEL_PATH)\n",
    "# serialize the label encoder to disk\n",
    "print(\"[INFO] saving label encoder...\")\n",
    "f = open(LE_PATH, \"wb\")\n",
    "f.write(pickle.dumps(le))\n",
    "f.close()\n",
    "# plot the training loss and accuracy\n",
    "plt.style.use(\"ggplot\")\n",
    "plt.figure()\n",
    "plt.plot(H[\"total_train_loss\"], label=\"total_train_loss\")\n",
    "plt.plot(H[\"total_val_loss\"], label=\"total_val_loss\")\n",
    "plt.plot(H[\"train_class_acc\"], label=\"train_class_acc\")\n",
    "plt.plot(H[\"val_class_acc\"], label=\"val_class_acc\")\n",
    "plt.title(\"Total Training Loss and Classification Accuracy on Dataset\")\n",
    "plt.xlabel(\"Epoch #\")\n",
    "plt.ylabel(\"Loss/Accuracy\")\n",
    "plt.legend(loc=\"lower left\")\n",
    "# save the training plot\n",
    "plotPath = os.path.sep.join([PLOTS_PATH, \"training.png\"])\n",
    "plt.savefig(plotPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "06a4afe4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "330ebeb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: ipykernel_launcher.py [-h] -i INPUT\n",
      "ipykernel_launcher.py: error: the following arguments are required: -i/--input\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 2\n"
     ]
    }
   ],
   "source": [
    "ap = argparse.ArgumentParser()\n",
    "ap.add_argument(\"-i\", \"--input\", required=True, help=\"path to input image/text file of image paths\")\n",
    "args = vars(ap.parse_args())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f92fc999",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76b56a76",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55e51d41",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bc1724f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fadc9ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "861aa420",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffdbfad6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb7b84cc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f2d6727",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2081ed8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d84cf481",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca42f63a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0998755b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae0888ff",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
